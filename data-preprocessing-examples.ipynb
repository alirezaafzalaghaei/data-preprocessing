{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b>Data preprocessing</b></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.snrazavi.ir/imgs/iris.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :               [5.88660714 3.05178571 3.79642857 1.22232143] \n",
      "standard deviation : [0.86741565 0.43424445 1.79264014 0.77916047] \n"
     ]
    }
   ],
   "source": [
    "print(\"mean :               %s \" % X_train.mean(axis=0))\n",
    "print(\"standard deviation : %s \" % X_train.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sample before  transforming :  [5.1 3.5 1.4 0.2]\n",
      "First sample after   transforming :  [-0.9  1.  -1.3 -1.3]\n",
      "First sample inverse transforming :  [5.1 3.5 1.5 0.2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "first = iris.data[0]\n",
    "first_scaled = scaler.transform(iris.data[0:1]).round(1)[0]\n",
    "first_rescaled =  scaler.inverse_transform(first_scaled).round(1)\n",
    "print(\"First sample before  transforming : \", first)\n",
    "print(\"First sample after   transforming : \", first_scaled)\n",
    "print(\"First sample inverse transforming : \", first_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :               [ 0. -0.  0.  0.] \n",
      "standard deviation : [1. 1. 1. 1.] \n"
     ]
    }
   ],
   "source": [
    "print(\"mean :               %s \" % X_train_scaled.mean(axis=0).round(8))\n",
    "print(\"standard deviation : %s \" % X_train_scaled.std(axis=0).round(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before normalization: 26%\n",
      "Accuracy after  normalization: 97%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kwargs = dict(hidden_layer_sizes=(5, 3, 2), activation = 'relu', max_iter = 500, random_state=1)\n",
    "\n",
    "\n",
    "# classify iris without normalization\n",
    "clf = MLPClassifier(**kwargs).fit(X_train,y_train)\n",
    "without_normalization = clf.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "# classify iris after normalization\n",
    "clf = MLPClassifier(**kwargs).fit(X_train_scaled,y_train)\n",
    "with_normalization = clf.score(X_test_scaled,y_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy before normalization: {:2d}%'.format(int(without_normalization*100)))\n",
    "print('Accuracy after  normalization: {:2d}%'.format(int(with_normalization*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www.snrazavi.ir/imgs/digits.png' width='50%'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "%matplotlib inline\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X, y= digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimention before PCA:  64\n",
      "Dataset dimention after  PCA:  41\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2619504828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "img_num = np.random.randint(0,X.shape[0])\n",
    "\n",
    "pca = PCA(0.99, random_state=0)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "tmp = X[img_num].reshape(8,8)\n",
    "tmp_inv = pca.inverse_transform(X_pca[img_num]).reshape(8,8)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "fig.suptitle('Target is %s' % (y[img_num]), fontsize=14, fontweight='bold')\n",
    "ax1.imshow(tmp,cmap='gray')\n",
    "ax2.imshow(tmp_inv,cmap='gray')\n",
    "ax1.set_title('Before PCA')\n",
    "ax2.set_title('After PCA')\n",
    "print(\"Dataset dimention before PCA: \", X.shape[1])\n",
    "print(\"Dataset dimention after  PCA: \", X_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before PCA: 93% in 2.84s\n",
      "Accuracy after  PCA: 95% in 1.32s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kwargs = dict(hidden_layer_sizes=(30, 25,20, 20, 10), activation = 'relu', max_iter = 150, random_state=1)\n",
    "\n",
    "# \n",
    "\n",
    "# classify digits without pca\n",
    "tic1 = time.time()\n",
    "clf = MLPClassifier(**kwargs).fit(X_train, y_train)\n",
    "without_pca = clf.score(X_test, y_test)\n",
    "toc1 = time.time()\n",
    "\n",
    "time.sleep(.2)\n",
    "\n",
    "# classify digits after pca\n",
    "tic2 = time.time()\n",
    "clf = MLPClassifier(**kwargs).fit(X_train_pca, y_train_pca)\n",
    "with_pca = clf.score(X_test_pca, y_test_pca)\n",
    "toc2 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy before PCA: {:2d}% in {:.2f}s'.format(int(without_pca*100),toc1-tic1))\n",
    "print('Accuracy after  PCA: {:2d}% in {:.2f}s'.format(int(with_pca*100),toc2-tic2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Normalization and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dimension after PCA is 44\n",
      "Classification score after normalization and PCA is 0.9711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "digits = load_digits()\n",
    "X,y = digits.data,digits.target\n",
    "\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "X = PCA(0.99, random_state=0).fit_transform(X)\n",
    "\n",
    "print('New dimension after PCA is %s' % X.shape[1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,stratify=y, random_state=0)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(30, 25, 15, 10), activation = 'tanh', max_iter = 500, random_state=1).fit(X_train, y_train)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "\n",
    "print('Classification score after normalization and PCA is %.4f' %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## internet advertisements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1549</th>\n",
       "      <th>1550</th>\n",
       "      <th>1551</th>\n",
       "      <th>1552</th>\n",
       "      <th>1553</th>\n",
       "      <th>1554</th>\n",
       "      <th>1555</th>\n",
       "      <th>1556</th>\n",
       "      <th>1557</th>\n",
       "      <th>1558</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>468</td>\n",
       "      <td>8.2105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>230</td>\n",
       "      <td>6.9696</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>460</td>\n",
       "      <td>7.7966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>234</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 1560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    0    1       2  3  4  5  6  7  8  ...   1549  1550  1551  \\\n",
       "0            0  125  125       1  1  0  0  0  0  0  ...      0     0     0   \n",
       "1            1   57  468  8.2105  1  0  0  0  0  0  ...      0     0     0   \n",
       "2            2   33  230  6.9696  1  0  0  0  0  0  ...      0     0     0   \n",
       "3            3   60  468     7.8  1  0  0  0  0  0  ...      0     0     0   \n",
       "4            4   60  468     7.8  1  0  0  0  0  0  ...      0     0     0   \n",
       "5            5   60  468     7.8  1  0  0  0  0  0  ...      0     0     0   \n",
       "6            6   59  460  7.7966  1  0  0  0  0  0  ...      0     0     0   \n",
       "7            7   60  234     3.9  1  0  0  0  0  0  ...      0     0     0   \n",
       "8            8   60  468     7.8  1  0  0  0  0  0  ...      0     0     0   \n",
       "9            9   60  468     7.8  1  0  0  0  0  0  ...      0     0     0   \n",
       "10          10  NaN  NaN     NaN  1  0  0  0  0  0  ...      0     0     0   \n",
       "\n",
       "    1552  1553  1554  1555  1556  1557  1558  \n",
       "0      0     0     0     0     0     0   ad.  \n",
       "1      0     0     0     0     0     0   ad.  \n",
       "2      0     0     0     0     0     0   ad.  \n",
       "3      0     0     0     0     0     0   ad.  \n",
       "4      0     0     0     0     0     0   ad.  \n",
       "5      0     0     0     0     0     0   ad.  \n",
       "6      0     0     0     0     0     0   ad.  \n",
       "7      0     0     0     0     0     0   ad.  \n",
       "8      0     0     0     0     0     0   ad.  \n",
       "9      0     0     0     0     0     0   ad.  \n",
       "10     0     0     0     0     0     0   ad.  \n",
       "\n",
       "[11 rows x 1560 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data =  pd.read_csv('add.csv')\n",
    "data = data.replace(r'^\\s*\\?\\s*$', np.nan,regex=True)\n",
    "data.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    903\n",
       "1    901\n",
       "2    910\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,1:4].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1548</th>\n",
       "      <th>1549</th>\n",
       "      <th>1550</th>\n",
       "      <th>1551</th>\n",
       "      <th>1552</th>\n",
       "      <th>1553</th>\n",
       "      <th>1554</th>\n",
       "      <th>1555</th>\n",
       "      <th>1556</th>\n",
       "      <th>1557</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.305837</td>\n",
       "      <td>-0.274088</td>\n",
       "      <td>-0.567039</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.150373</td>\n",
       "      <td>2.824037</td>\n",
       "      <td>0.837047</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.664329</td>\n",
       "      <td>0.674318</td>\n",
       "      <td>0.595409</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.086128</td>\n",
       "      <td>2.824037</td>\n",
       "      <td>0.757111</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.086128</td>\n",
       "      <td>2.824037</td>\n",
       "      <td>0.757111</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1558 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2     3      4      5      6      7      8  \\\n",
       "0  1.305837 -0.274088 -0.567039  True  False  False  False  False  False   \n",
       "1 -0.150373  2.824037  0.837047  True  False  False  False  False  False   \n",
       "2 -0.664329  0.674318  0.595409  True  False  False  False  False  False   \n",
       "3 -0.086128  2.824037  0.757111  True  False  False  False  False  False   \n",
       "4 -0.086128  2.824037  0.757111  True  False  False  False  False  False   \n",
       "\n",
       "       9  ...     1548   1549   1550   1551   1552   1553   1554   1555  \\\n",
       "0  False  ...    False  False  False  False  False  False  False  False   \n",
       "1  False  ...    False  False  False  False  False  False  False  False   \n",
       "2  False  ...    False  False  False  False  False  False  False  False   \n",
       "3  False  ...    False  False  False  False  False  False  False  False   \n",
       "4  False  ...    False  False  False  False  False  False  False  False   \n",
       "\n",
       "    1556   1557  \n",
       "0  False  False  \n",
       "1  False  False  \n",
       "2  False  False  \n",
       "3  False  False  \n",
       "4  False  False  \n",
       "\n",
       "[5 rows x 1558 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy \n",
    "from sklearn.preprocessing import LabelBinarizer,StandardScaler\n",
    "\n",
    "# data.dropna(inplace=True)\n",
    "\n",
    "X = data.iloc[:,1:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "\n",
    "X.iloc[:,:3] = X.iloc[:,:3].astype(float)\n",
    "X.iloc[:,3:] = X.iloc[:,3:].astype(bool)\n",
    "X.iloc[:,:3] = X.iloc[:,:3].replace(np.NaN,X.iloc[:,:3].mean())\n",
    "\n",
    "\n",
    "\n",
    "X.iloc[:,:3] = StandardScaler().fit_transform(X.iloc[:,:3])\n",
    "X_new = PCA(0.98, random_state=0).fit_transform(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension before PCA is 1558 and after PCA is 349\n",
      "Classification score before normalization and PCA is 97.32% in 4.89 seconds\n",
      "Classification score after  normalization and PCA is 97.68% in 2.72 seconds\n"
     ]
    }
   ],
   "source": [
    "print('dimension before PCA is %s and after PCA is %s' % (X.shape[1],X_new.shape[1]))\n",
    "\n",
    "kwargs = dict(hidden_layer_sizes=(100,50,25,5), activation = 'relu', max_iter = 200, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,stratify=y, random_state=0)\n",
    "tic = time.time()\n",
    "clf = MLPClassifier(**kwargs).fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "toc = time.time()\n",
    "print('Classification score before normalization and PCA is {:.2f}% in {:.2f} seconds'.format(round(score*100,2),toc-tic))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.25,stratify=y, random_state=0)\n",
    "tic = time.time()\n",
    "clf = MLPClassifier(**kwargs).fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "toc = time.time()\n",
    "\n",
    "print('Classification score after  normalization and PCA is {:.2f}% in {:.2f} seconds'.format(round(score*100,2),toc-tic))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
