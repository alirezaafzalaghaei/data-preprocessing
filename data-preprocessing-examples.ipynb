{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"><b>Data preprocessing</b></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://www.snrazavi.ir/imgs/iris.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = warn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :               [5.88660714 3.05178571 3.79642857 1.22232143] \n",
      "standard deviation : [0.86741565 0.43424445 1.79264014 0.77916047] \n"
     ]
    }
   ],
   "source": [
    "print(\"mean :               %s \" % X_train.mean(axis=0))\n",
    "print(\"standard deviation : %s \" % X_train.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sample before  transforming :  [5.1 3.5 1.4 0.2]\n",
      "First sample after   transforming :  [-0.9  1.  -1.3 -1.3]\n",
      "First sample inverse transforming :  [5.1 3.5 1.5 0.2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "first = iris.data[0]\n",
    "first_scaled = scaler.transform(iris.data[0:1]).round(1)[0]\n",
    "first_rescaled =  scaler.inverse_transform(first_scaled).round(1)\n",
    "print(\"First sample before  transforming : \", first)\n",
    "print(\"First sample after   transforming : \", first_scaled)\n",
    "print(\"First sample inverse transforming : \", first_rescaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :               [ 0. -0.  0.  0.] \n",
      "standard deviation : [1. 1. 1. 1.] \n"
     ]
    }
   ],
   "source": [
    "print(\"mean :               %s \" % X_train_scaled.mean(axis=0).round(8))\n",
    "print(\"standard deviation : %s \" % X_train_scaled.std(axis=0).round(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before normalization: 26%\n",
      "Accuracy after  normalization: 97%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kwargs = dict(hidden_layer_sizes=(5, 3, 2), activation = 'relu', max_iter = 500, random_state=1)\n",
    "\n",
    "\n",
    "# classify iris without normalization\n",
    "clf = MLPClassifier(**kwargs).fit(X_train,y_train)\n",
    "without_normalization = clf.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "# classify iris after normalization\n",
    "clf = MLPClassifier(**kwargs).fit(X_train_scaled,y_train)\n",
    "with_normalization = clf.score(X_test_scaled,y_test)\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy before normalization: {:2d}%'.format(int(without_normalization*100)))\n",
    "print('Accuracy after  normalization: {:2d}%'.format(int(with_normalization*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='http://www.snrazavi.ir/imgs/digits.png' width='50%'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "%matplotlib inline\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X, y= digits.data, digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimention before PCA:  64\n",
      "Dataset dimention after  PCA:  41\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEVCAYAAADARw+NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAGExJREFUeJzt3XuUXWV9xvHnyWSSEC6dcr8ECahEwdZAAwoIRLyhUAxLVFBuoo1Ca9G6lqB22VAvta0itN4aQeMSEOWmIilyjZQWIglENCQiwSAhgYA4kJBAmOHXP/Ye2I5n5uwhe58z75nvZ61ZOZd93vd3kneevGefvd/tiBAAIB3j2l0AAGBkCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3EADtlfZDtsXtLsWYDCCGyNie2UeaMP9zGl3nYPZflmhvhNLvOROSQslraig7/fYvsv207Yft32Z7b02t12MXePbXQCSc5ekh/PbUyTtlt9eIumZ/PaqzenA9oSI2LQ5bWyuiDiminZsf1DSN/K790vaQdJxkl5n+9URsbaKfjC2MOPGiETEsRHx2oh4raTiboTnH4+IC2xvY/tH+Qz9KdvP2L7X9hzb3QMvsn1rPgu+wfYnba+W9FD+XI/t7+WvX2P7U7Yvyre/r9DGONsftn13Pqvtzft+Zf78ByT9plDrdwf6HOp9NtpVYvtjtu/J63nS9q+G25Vie5Kkf8nvfj8iXippH0lPSdpZ0tlN/8KBBphxoy6TJR2jbHb+a2UzzZdL+idJEyV9YtD2h0qamW87IX/sW5KOzW+vknSWGk82virpQ/nteyRtn/d9qO39Ja1V9olger7NCkmP5duWYvtYSV8s9GFJe0p6maQPDPGy10j68/z2FZIUEats/1zS6yW9pWz/QBEzbtSlV9IrI2KXiNg/InaXdGn+3PENtp8g6ciI2FfSK2zvrRdC+7yImCbpFZL6iy+y/TJJH8zvvj9//R6SlisLzbMi4seS3ll42Zz8k8Hfj+D97J3/+dOI2Dci9pHUI+nNw7xm98Lt4i6RR/I/XzKC/oHnEdyoS5+kU23/Jt9NEnohsHdtsP3SiLhBkiKiX9KrCs99L398taSfDXrdAcpmv5J0Yd7PRmUhL0mv3ex3kvmppGclvcX2o7b/V9J5kobbF+8RPg6Uwq4S1OVTynZtSNJKZbPMgS8zuxps/3CDxwYMt4RlMQSLX5AOeHDYKkuKiCW295X0HmW7XKZLOljSbNsHRsRdDV72u8LtHRvcrqQ2jD0EN+oyMNO9JyL2td0l6Rq9cBRKM78s3D5O0h22d5V0+KDt7ijcvigivjRwx/YMSQNfhG4obLdlyRqel++66YuIc/L7W0h6XNIkSYcpO9pmsIWS/qBsl807JF1me4qkA/Pnrx1pHYDErhLU5+78z31s369s9nlA2RdHxG8kXZXf/bjt5ZKWadBkI9/um/ndL+ZHsfzC9uPKQv0N+XMPK9vvLkn/bnuh7TNG8H6OkLTC9kO271T2Beek/Lm7G70gIp6W9I/53XfbXiFpqbL/ONZK+rcR9A88j+BGXT4j6buSnpC0jaSLJM0dYRunKftCc4OyWeu5kq7Pn9tY2O5Dkj6iLEB3Una0xxpJX5P0Q0mKiOck/Y2ywJ2sbNY7ki8HFyv7j2STpFcqC987Jb0vIm4e6kUR8TVJJ0v6hbJdRc9JulLSIREx3O4hYEjmCjgYrWy/RNLafOYq2zsqm7FuL+m7EXFyO+sD2oUZN0azd0l6yPZ1tq9Rdoz39pLWSfpCWysD2ojg3ky2T7f9iO31trdrdz0d5m5J9ynbrfFmZbtMLpF0YESUPnkG5dnewvbVtp+wfVm760FjYz648y+zNubB+wfb19jevfkrpfzU7XMlvTkitoqI39dc6xzbz+a19tr+P9sHFZ7fxfaF+enh62wvt32O7S0L29j2/bZHffBFxHUR8ZqI6ImI7ojYLSLeGxHL211b6mwvyMf7xEFPHafse4LtIuKdtk+1fWvFfZ9quz8fx0/aXmL76MLz29g+z/bv8m3uy+9vX/I9dLwxH9y5v46IrSTtoux44/8s+bqdlB1ZsHSkHeYB+mL+/r+f17qDpFslXZm3ta2k2yRtIemgiNha0puUnd330sLrD1N2HPFetksf5YHOYXuqsiUGQtnSAEV7SLo3Ivoq6muoQ45vy8dxj6QLJf3A9ra2J0i6UdK+ko5U9sX2wZJ+rxcOo2z2HjoewV2Qfwl2ubKFgCRJtifa/mL+v/8jtr+Rf5zcW9k+V0nqtX1Tvv3Btu/IP2reYfvgQlsLbH8uP+tug7Lw/LPCLPkh25/Nj3luVuuzkr6jbLGi7ST9g7J9vydGxMp8mwcj4syIKB6udoqkH0man9/G2HOypNslzVNhDNg+R9KnlR26uN723ypb2fCggU95+XYNfyfy52Y6W6DrLNsPS/r2cIXkR/t8S9mEY6+8tpcoW7Tsnoh4LiLWRsRnImJ+s/cwVhDcBbYnS3q3sgEx4F+VrVMxXdmCQrtJ+nRE3KtsViBJPRFxRD7rvUbSfygL03MlXTNo3/dJkmZL2lrSA8rCty9vez9l+3KHWrSoWOtESadKWhURj0l6o6Qr81+E4d7fcZIuzn+Oz2c4GFtO1gtj4C22d5KkiPgnSZ9X/qkuIgYW77otv9+Tv77h70Sh/Z0lbats9j57uELyGfkHJK1XtoLjGyVdGxHrX8x7GDMiYkz/KDsde72ykzP6JK2W9Bf5c1a2BOdLC9sfJOm3+e2pyj6qjc/vnyTp54Pav03SqfntBZL+ufDcTspO0d6i8NgJkm4eotY5yo4j7lV2AsdNkv4qf+43kj7U5L2eKOlRZSexTMzbObbd/wb8tO5H0uuUrbmyfX5/uaSPFp6fo+wM1IH7p0q6tXC/2e/EzHyMThqmhlPz37VeZas03i7pjflz10v6wua8h7HwwynvmVkRcUO+i+Ltkn5mex9lJ0tMlrTYfn5JDKvxWhtStnjSA4Mee0B/fJp3cX2KPZSdkr2m0P44Db+GxQ8iotEVXH6vbB/9cE7JX98nqc/2lfljVw3/MnSQUyRdF9mnNCk7SucUSV8u+fod1Px34tHIj70fxu0R8boGj5cdx5vzHpJHcBdEtirdlbb/S9n/6lcqO0Nv34h4qEQTq5WFcdFL9MdrUhTPeHpQ2Yx7+9j8L4NukHSs7XOiwe4SZ2tkHCHpQNvvyB+eLGmS7e0LvwToUPl+6HdJ6sr3P0vZJ68eZ1fj+UWDlw0+Q+8xNf+d2Jyz+m6Q9FnbW0bEU4OffJHvoeOwj7sgPzrj7cpOr16WB+A3JX3Z2Vl7sr2b7aEWwJ8vaW9n1xgcb/vdyr7o/EmjjSNijaTrJH0pPwRqnO2X2h68kFIZ5yr7Bv47tvco1Hqu7b9UthvnXknT9MLqdnsru0DBCS+iP6RnlrL1zPfRC2PglZL+R9k+40YekTRl4LuQF/E7MVLfVTahucL2K/Lfie2cXR3pbS/yPXQcgjtzte31kp6U9DlJp0TEwCF+Zyk7CeR2208qmxFMa9RIZMdxHy3pY8o+8n1c0tFNZrMnK7uIwD3KVpK7XM0/Kjbq+3Flh009K2mh7XXKDqt6Iq//FElfi4iHiz/KjhoYc9/Kj1GnSPp2RPxu0Bj4iqT3DnHo3k3KDnd92PbAOC79OzFSEfGMsi8olyvb3/2kpJ8rO2N24Yt8Dx2HtUoAIDHMuAEgMQQ3ACSG4AaAxBDcAJCYWr6BdXal7cpNmNC6s7OnTp3asr5abcWKFS3rq7+/v5Z2I6LlV0q3HYWTTirT3d3dfKOK7Lnnni3rq9UHPvz2t79tWV/PPvtsLe2WHde1HFVSV3C3MkznzZvXsr5abdasWS3rq7e3t/lGL0I7gnvcuHFRx+Rh5513rrzNoVxyySUt66uucBvKCSe07nSENWvW1NJu2XHNrhIASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJDcANAYghuAEhMqeC2faTtX9u+z/bZdRcFABha0+DOL6D7VUlvVXa5oBPyC+kCANqgzIz7QEn3RcT9EbFJ0qXKroQOAGiDMsG9m7KLdw5YlT/2R2zPtr3I9qKqigParTiuucwfRosyy7o2Wq3qT0ZwRMyVNFeqb3VAoNWK43rcuHGMa4wKZWbcqyTtXrg/RdLqesoBADRTJrjvkPRy23vaniDpeEk/rrcsAMBQmu4qiYg+238n6aeSuiR9KyKW1l4ZAKChUpcui4j5kubXXAsAoATOnASAxBDcAJAYghsAEkNwA0BiCG4ASAzBDQCJIbgBIDGuY+GciRMnxq677lp5u/Pmzau8zdGg1e9r1qxZyfcVEY3W0KnV5MmTY9q0aZW3e/7551fe5mhw8cUXt7S/o446qmV9nXbaaZW32dvbq76+vlLjmhk3ACSG4AaAxBDcAJAYghsAEkNwA0BiCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQ0DW7b37K91vavWlEQAGB4ZWbc8yQdWXMdAICSmgZ3RNwi6fEW1AIAKKHUVd7LsD1b0mxJ6urqqqpZoK2K47q7u7vN1QCZyr6cjIi5ETEjImYQ3OgUxXE9fnxl8xxgs3BUCQAkhuAGgMSUORzwe5JukzTN9irb76+/LADAUJrutIuIE1pRCACgHHaVAEBiCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQmFoWX9h11101Z86cytvt6empvM2hTJ8+vWV9tdrMmTNb1tfUqVMrb3P16tWVt1nGjjvuqDPOOKPydrfddtvK2xzKAQcc0LK+IqJlfUnSoYce2rK+tt5668rbXLduXeltmXEDQGIIbgBIDMENAIkhuAEgMQQ3ACSG4AaAxBDcAJAYghsAEkNwA0BiCG4ASEyZa07ubvtm28tsL7V9ZisKAwA0Vmatkj5JH4uIO21vLWmx7esj4p6aawMANNB0xh0RayLizvz2OknLJO1Wd2EAgMZGtI/b9lRJ+0la2OC52bYX2V40klWugNGMcY3RqHRw295K0hWSPhIRTw5+PiLmRsSMiJhRx5KHQDswrjEalQpu293KQvviiLiy3pIAAMMpc1SJJV0oaVlEnFt/SQCA4ZSZcR8i6SRJR9hekv+8rea6AABDaHo4YETcKsktqAUAUAJnTgJAYghuAEgMwQ0AiSG4ASAxBDcAJIbgBoDEENwAkBiCGwASU2Y97hF75plntHLlysrb7enpqbzNsWjBggUt62vmzJmVt3n11VdX3mYZzz33nDZu3Fh5uytWrKi8zaGMG9e6uVp/f3/L+pKkW265pWV9HXnkkZW3ecUVV5Telhk3ACSG4AaAxBDcAJAYghsAEkNwA0BiCG4ASAzBDQCJIbgBIDEENwAkpszFgifZ/rntX9heavucVhQGAGiszCnvz0g6IiLW2+6WdKvt/46I22uuDQDQQJmLBYek9fnd7vwn6iwKADC0Uvu4bXfZXiJpraTrI2Jhg21m215ke9GGDRuqrhNoi+K4Xr9+ffMXAC1QKrgjoj8ipkuaIulA269qsM3ciJgRETMmT55cdZ1AWxTH9VZbbdXucgBJIzyqJCJ6JS2QVP2ahgCAUsocVbKD7Z789haS3ihped2FAQAaK3NUyS6SvmO7S1nQ/yAiflJvWQCAoZQ5quRuSfu1oBYAQAmcOQkAiSG4ASAxBDcAJIbgBoDEENwAkBiCGwASQ3ADQGIIbgBITJkzJ0esv79fvb29lbe7cuXKytsci1r59zhr1qzK27zxxhsrb7OMjRs3aunSpZW3293dXXmbQ+nv729ZX11dXS3rS5IeeOCBlvV17LHHVt7m/PnzS2/LjBsAEkNwA0BiCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJTOrhtd9m+yzbXmwSANhrJjPtMScvqKgQAUE6p4LY9RdJRki6otxwAQDNlZ9znSfq4pOdqrAUAUELT4LZ9tKS1EbG4yXazbS+yvWjjxo2VFQi0U3FcP/300+0uB5BUbsZ9iKRjbK+UdKmkI2xfNHijiJgbETMiYsYWW2xRcZlAexTH9aRJk9pdDiCpRHBHxCciYkpETJV0vKSbIuLE2isDADTEcdwAkJgRXQEnIhZIWlBLJQCAUphxA0BiCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABIzohNwylq3bp0WLFhQebvz5s2rvM2xaObMmS3ra/r06ZW32a61cJ5++mktX7688nbPOOOMytscSldXV8v66uvra1lfknT44Ye3rK9p06ZV3uZI1sJhxg0AiSG4ASAxBDcAJIbgBoDEENwAkBiCGwASQ3ADQGIIbgBIDMENAIkpdeZkfoX3dZL6JfVFxIw6iwIADG0kp7y/PiIeq60SAEAp7CoBgMSUDe6QdJ3txbZn11kQAGB4ZXeVHBIRq23vKOl628sj4pbiBnmgz5ak7u7uissE2qM4ridOnNjmaoBMqRl3RKzO/1wr6SpJBzbYZm5EzIiIGePH17JaLNByxXHNhASjRdPgtr2l7a0Hbkt6s6Rf1V0YAKCxMlPjnSRdZXtg+0si4tpaqwIADKlpcEfE/ZJe3YJaAAAlcDggACSG4AaAxBDcAJAYghsAEkNwA0BiCG4ASAzBDQCJIbgBIDG1LCqyceNGLVmypPJ2e3t7K29zKAsWLGhZX3X8XQ3nzDPPbFlfH/3oRytvs5XjoGjDhg1avHhx5e0+8cQTlbc5lPnz57esr6VLl7asL0k6/fTTW9bX2WefXXmbIxkHzLgBIDEENwAkhuAGgMQQ3ACQGIIbABJDcANAYghuAEgMwQ0AiSG4ASAxBDcAJKZUcNvusX257eW2l9k+qO7CAACNlV2r5HxJ10bEcbYnSJpcY00AgGE0DW7b20g6TNKpkhQRmyRtqrcsAMBQyuwq2UvSo5K+bfsu2xfY3nLwRrZn215ke1HlVQJtUhzXEdHucgBJ5YJ7vKT9JX09IvaT9JSkP1nTMCLmRsSMiJhRcY1A2xTHte12lwNIKhfcqyStioiF+f3LlQU5AKANmgZ3RDws6UHb0/KH3iDpnlqrAgAMqexRJR+WdHF+RMn9kt5XX0kAgOGUCu6IWCKJfdcAMApw5iQAJIbgBoDEENwAkBiCGwASQ3ADQGIIbgBIDMENAIkhuAEgMa5jxTPbtSyj1tPTU0ezDf3whz9sWV+HH354y/qSpPPPP79lfc2ZM6fyNtetW6e+vr6Wr/g0bty46O7urrzdnXbaqfI2h3LRRRe1rK/DDjusZX1J0le+8pWW9fX5z3++8jYfe+wxbdq0qdS4ZsYNAIkhuAEgMQQ3ACSG4AaAxBDcAJAYghsAEkNwA0BiCG4ASAzBDQCJaRrctqfZXlL4edL2R1pRHADgTzW95mRE/FrSdEmy3SXpIUlX1VwXAGAII91V8gZJKyLigTqKAQA0V+oq7wXHS/peoydsz5Y0e7MrAkYRxjVGo9IzbtsTJB0j6bJGz0fE3IiYEREzqioOaLfiuLZbviAh0NBIdpW8VdKdEfFIXcUAAJobSXCfoCF2kwAAWqdUcNueLOlNkq6stxwAQDOlvpyMiA2Stqu5FgBACZw5CQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJDcANAYghuAEiMI6L6Ru1HJY2WpV+3l/RYu4uoQae+L6n5e9sjInZoVTEDRtm4ljp3DIzV91V6XNcS3KOJ7UWduGJhp74vqbPfW5U69e+J99Ucu0oAIDEENwAkZiwE99x2F1CTTn1fUme/typ16t8T76uJjt/HDQCdZizMuAGgo3RkcNve3fbNtpfZXmr7zHbXVDXbXbbvsv2TdtdSFds9ti+3vTz/tzuo3TWNNp0+tjtxXEvVj+2RXuU9FX2SPhYRd9reWtJi29dHxD3tLqxCZ0paJmmbdhdSofMlXRsRx+UXp57c7oJGoU4f2504rqWKx3ZHzrgjYk1E3JnfXqdsIOzW3qqqY3uKpKMkXdDuWqpiextJh0m6UJIiYlNE9La3qtGnk8d2J45rqZ6x3ZHBXWR7qqT9JC1sbyWVOk/SxyU91+5CKrSXpEclfTv/qHyB7S3bXdRo1oFjuxPHtVTD2O7o4La9laQrJH0kIp5sdz1VsH20pLURsbjdtVRsvKT9JX09IvaT9JSks9tb0ujVaWO7g8e1VMPY7tjgtt2tbGBfHBGddHX6QyQdY3ulpEslHWH7ovaWVIlVklZFxMDs8XJlgx2DdOjY7tRxLdUwtjsyuG1b2f6kZRFxbrvrqVJEfCIipkTEVEnHS7opIk5sc1mbLSIelvSg7Wn5Q2+Q1ClfuFWmU8d2p45rqZ6x3alHlRwi6SRJv7S9JH/skxExv401obkPS7o4/9b9fknva3M9oxFjO02Vjm3OnASAxHTkrhIA6GQENwAkhuAGgMQQ3ACQGIIbABJDcANAYghuAEgMwQ0Aifl/is3MLHR1BI0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f019957fb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "img_num = np.random.randint(0,X.shape[0])\n",
    "\n",
    "pca = PCA(0.99, random_state=0)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "tmp = X[img_num].reshape(8,8)\n",
    "tmp_inv = pca.inverse_transform(X_pca[img_num]).reshape(8,8)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "fig.suptitle('Target is %s' % (y[img_num]), fontsize=14, fontweight='bold')\n",
    "ax1.imshow(tmp,cmap='gray')\n",
    "ax2.imshow(tmp_inv,cmap='gray')\n",
    "ax1.set_title('Before PCA')\n",
    "ax2.set_title('After PCA')\n",
    "print(\"Dataset dimention before PCA: \", X.shape[1])\n",
    "print(\"Dataset dimention after  PCA: \", X_pca.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score without PCA: 0.9378 in 2.38s\n",
      "Score with    PCA: 0.9511 in 1.13s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "kwargs = dict(hidden_layer_sizes=(30, 25,20, 20, 10), activation = 'relu', max_iter = 150, random_state=1)\n",
    "\n",
    "# \n",
    "\n",
    "# classify iris without pca\n",
    "tic1 = time.time()\n",
    "clf = MLPClassifier(**kwargs).fit(X_train, y_train)\n",
    "without_pca = clf.score(X_test, y_test)\n",
    "toc1 = time.time()\n",
    "\n",
    "time.sleep(.2)\n",
    "\n",
    "# classify iris after pca\n",
    "tic2 = time.time()\n",
    "clf = MLPClassifier(**kwargs).fit(X_train_pca, y_train_pca)\n",
    "with_pca = clf.score(X_test_pca, y_test_pca)\n",
    "toc2 = time.time()\n",
    "\n",
    "\n",
    "\n",
    "print('Score without PCA: %.4f in %.2fs'%(without_pca, toc1-tic1))\n",
    "print('Score with    PCA: %.4f in %.2fs'%(with_pca, toc2-tic2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Normalization and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dimension after PCA is 44\n",
      "Classification score after normalization and PCA is 0.9711\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "digits = load_digits()\n",
    "X,y = digits.data,digits.target\n",
    "\n",
    "X = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "X = PCA(0.99, random_state=0).fit_transform(X)\n",
    "\n",
    "print('New dimension after PCA is %s' % X.shape[1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,stratify=y, random_state=0)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(30, 25, 15, 10), activation = 'tanh', max_iter = 500, random_state=1).fit(X_train, y_train)\n",
    "\n",
    "score = clf.score(X_test, y_test)\n",
    "\n",
    "print('Classification score after normalization and PCA is %.4f' %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## internet advertisements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1549</th>\n",
       "      <th>1550</th>\n",
       "      <th>1551</th>\n",
       "      <th>1552</th>\n",
       "      <th>1553</th>\n",
       "      <th>1554</th>\n",
       "      <th>1555</th>\n",
       "      <th>1556</th>\n",
       "      <th>1557</th>\n",
       "      <th>1558</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>468</td>\n",
       "      <td>8.2105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>230</td>\n",
       "      <td>6.9696</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "      <td>460</td>\n",
       "      <td>7.7966</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>234</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>60</td>\n",
       "      <td>468</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ad.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 1560 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0    0    1       2  3  4  5  6  7  8  ...   1549  1550  1551  \\\n",
       "0            0  125  125       1  1  0  0  0  0  0  ...      0     0     0   \n",
       "1            1   57  468  8.2105  1  0  0  0  0  0  ...      0     0     0   \n",
       "2            2   33  230  6.9696  1  0  0  0  0  0  ...      0     0     0   \n",
       "3            3   60  468     7.8  1  0  0  0  0  0  ...      0     0     0   \n",
       "4            4   60  468     7.8  1  0  0  0  0  0  ...      0     0     0   \n",
       "5            5   60  468     7.8  1  0  0  0  0  0  ...      0     0     0   \n",
       "6            6   59  460  7.7966  1  0  0  0  0  0  ...      0     0     0   \n",
       "7            7   60  234     3.9  1  0  0  0  0  0  ...      0     0     0   \n",
       "8            8   60  468     7.8  1  0  0  0  0  0  ...      0     0     0   \n",
       "9            9   60  468     7.8  1  0  0  0  0  0  ...      0     0     0   \n",
       "10          10  NaN  NaN     NaN  1  0  0  0  0  0  ...      0     0     0   \n",
       "\n",
       "    1552  1553  1554  1555  1556  1557  1558  \n",
       "0      0     0     0     0     0     0   ad.  \n",
       "1      0     0     0     0     0     0   ad.  \n",
       "2      0     0     0     0     0     0   ad.  \n",
       "3      0     0     0     0     0     0   ad.  \n",
       "4      0     0     0     0     0     0   ad.  \n",
       "5      0     0     0     0     0     0   ad.  \n",
       "6      0     0     0     0     0     0   ad.  \n",
       "7      0     0     0     0     0     0   ad.  \n",
       "8      0     0     0     0     0     0   ad.  \n",
       "9      0     0     0     0     0     0   ad.  \n",
       "10     0     0     0     0     0     0   ad.  \n",
       "\n",
       "[11 rows x 1560 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data =  pd.read_csv('add.csv')\n",
    "data = data.replace(r'^\\s*\\?\\s*$', np.nan,regex=True)\n",
    "data.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    903\n",
       "1    901\n",
       "2    910\n",
       "dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,1:4].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1548</th>\n",
       "      <th>1549</th>\n",
       "      <th>1550</th>\n",
       "      <th>1551</th>\n",
       "      <th>1552</th>\n",
       "      <th>1553</th>\n",
       "      <th>1554</th>\n",
       "      <th>1555</th>\n",
       "      <th>1556</th>\n",
       "      <th>1557</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.305837</td>\n",
       "      <td>-0.274088</td>\n",
       "      <td>-0.567039</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.150373</td>\n",
       "      <td>2.824037</td>\n",
       "      <td>0.837047</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.664329</td>\n",
       "      <td>0.674318</td>\n",
       "      <td>0.595409</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.086128</td>\n",
       "      <td>2.824037</td>\n",
       "      <td>0.757111</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.086128</td>\n",
       "      <td>2.824037</td>\n",
       "      <td>0.757111</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1558 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2     3      4      5      6      7      8  \\\n",
       "0  1.305837 -0.274088 -0.567039  True  False  False  False  False  False   \n",
       "1 -0.150373  2.824037  0.837047  True  False  False  False  False  False   \n",
       "2 -0.664329  0.674318  0.595409  True  False  False  False  False  False   \n",
       "3 -0.086128  2.824037  0.757111  True  False  False  False  False  False   \n",
       "4 -0.086128  2.824037  0.757111  True  False  False  False  False  False   \n",
       "\n",
       "       9  ...     1548   1549   1550   1551   1552   1553   1554   1555  \\\n",
       "0  False  ...    False  False  False  False  False  False  False  False   \n",
       "1  False  ...    False  False  False  False  False  False  False  False   \n",
       "2  False  ...    False  False  False  False  False  False  False  False   \n",
       "3  False  ...    False  False  False  False  False  False  False  False   \n",
       "4  False  ...    False  False  False  False  False  False  False  False   \n",
       "\n",
       "    1556   1557  \n",
       "0  False  False  \n",
       "1  False  False  \n",
       "2  False  False  \n",
       "3  False  False  \n",
       "4  False  False  \n",
       "\n",
       "[5 rows x 1558 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy \n",
    "from sklearn.preprocessing import LabelBinarizer,StandardScaler\n",
    "# data.dropna(inplace=True)\n",
    "# data['0'].replace(np.NaN,data['0'].mean())\n",
    "X = data.iloc[:,1:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "\n",
    "X.iloc[:,:3] = X.iloc[:,:3].astype(float)\n",
    "X.iloc[:,3:] = X.iloc[:,3:].astype(bool)\n",
    "X.iloc[:,:3] = X.iloc[:,:3].replace(np.NaN,X.iloc[:,:3].mean())\n",
    "\n",
    "\n",
    "\n",
    "X.iloc[:,:3] = StandardScaler().fit_transform(X.iloc[:,:3])\n",
    "X_new = PCA(0.98, random_state=0).fit_transform(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension before PCA is 1558 and after PCA is 349\n",
      "Classification score before normalization and PCA is 97.32% in 4.67 seconds\n",
      "Classification score after  normalization and PCA is 97.68% in 2.61 seconds\n"
     ]
    }
   ],
   "source": [
    "print('dimension before PCA is %s and after PCA is %s' % (X.shape[1],X_new.shape[1]))\n",
    "\n",
    "kwargs = dict(hidden_layer_sizes=(100,50,25,5), activation = 'relu', max_iter = 200, random_state=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,stratify=y, random_state=0)\n",
    "tic = time.time()\n",
    "clf = MLPClassifier(**kwargs).fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "toc = time.time()\n",
    "print('Classification score before normalization and PCA is {:.2f}% in {:.2f} seconds'.format(round(score*100,2),toc-tic))\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.25,stratify=y, random_state=0)\n",
    "tic = time.time()\n",
    "clf = MLPClassifier(**kwargs).fit(X_train, y_train)\n",
    "score = clf.score(X_test, y_test)\n",
    "toc = time.time()\n",
    "\n",
    "print('Classification score after  normalization and PCA is {:.2f}% in {:.2f} seconds'.format(round(score*100,2),toc-tic))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
